{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import zipfile\n",
    "import osr\n",
    "from gdalconst import GA_ReadOnly\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLDAS SM Noah data using wget: generatet the file list\n",
    "# then follow this https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/\n",
    "year = np.arange(2022, 2023, 1)\n",
    "julian = np.arange(1,366,1)\n",
    "url = 'https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/'\n",
    "name = 'NLDAS_NOAH0125_H.A'\n",
    "ext = '.002.grb'\n",
    "f = open('R:/UnitedStates/ForDRI_project-NEW/Case_Study_2022_Growing_Season/SM/urls.txt','w')\n",
    "for y in year:\n",
    "    url_y = url+str(year)+'/'\n",
    "    for j in julian:\n",
    "        if j<10:\n",
    "            jjj = '00'+str(j)\n",
    "        elif j<100:\n",
    "            jjj = '0'+str(j)\n",
    "        else:\n",
    "            jjj = str(j)\n",
    "        yyyymmdd = datetime.datetime.strptime(str(y)+jjj,'%Y%j').date().strftime('%Y%m%d')\n",
    "        for h in range(0,24):\n",
    "            if h < 10:\n",
    "                hhhh = '0'+str(h)+'00'\n",
    "            else:\n",
    "                hhhh = str(h)+'00'\n",
    "            full_url = url+str(y)+'/'+jjj+'/'+name+yyyymmdd+'.'+hhhh+ext\n",
    "            f.write(full_url+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't work...\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import re\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "def getFile(url):\n",
    "    try:\n",
    "        html =urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        \n",
    "        bsObj = BeautifulSoup(html)\n",
    "        files = bsObj.findAll(\"a\")\n",
    "        flist = []\n",
    "        for link in files:\n",
    "            if 'href' in link.attrs:\n",
    "                flist.append(link.attrs['href'])\n",
    "                #print(link.attrs['href'])\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return flist\n",
    "\n",
    "\n",
    "\n",
    "odir = 'R:/UnitedStates/ForDRI_project-NEW/Case_Study_2022_Growing_Season/SM/'\n",
    "for i in range(1,2): # on the day downloaded the dataset, it has been updated to 253\n",
    "    if i < 10:\n",
    "        src = 'https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/2022/00'+str(i)+'/'\n",
    "    elif i < 100:\n",
    "        src = 'https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/2022/0'+str(i)+'/'\n",
    "    else:\n",
    "        src = 'https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/2022/'+str(i)+'/'\n",
    "    \n",
    "\n",
    "    flist = getFile(src)\n",
    "    if flist == None:\n",
    "        print(\"Title could not be found\")\n",
    "    else:\n",
    "        #print(flist)\n",
    "        for f in range(len(flist)):\n",
    "            if flist[f][-3:]=='grb' or flist[f][-3:]=='xml':\n",
    "                html = src+flist[f]\n",
    "                # Create an OpenerDirector with support for Basic HTTP Authentication...\n",
    "                auth_handler = urllib.request.HTTPBasicAuthHandler()\n",
    "                auth_handler.add_password(realm='NASA Earthdata ',\n",
    "                                        uri=html,\n",
    "                                        user='zbc123a',\n",
    "                                        passwd='NSO5804246tj')\n",
    "                opener = urllib.request.build_opener(auth_handler)\n",
    "                # ...and install it globally so it can be used with urlopen.\n",
    "                urllib.request.install_opener(opener)\n",
    "                r = requests.get(html, stream = True)\n",
    "                with open((odir+flist[f].split('/')[-1]), 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                print(html)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/2022/014/NLDAS_NOAH0125_H.A20220114.0000.002.grb\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "html = \"https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_NOAH0125_H.002/2022/014/NLDAS_NOAH0125_H.A20220114.0000.002.grb\"\n",
    "\n",
    "user='zbc123a'\n",
    "password='NSO5804246tj'\n",
    "session = requests.Session()\n",
    "session.auth = (user, password)\n",
    "auth = session.post(html)\n",
    "r = session.get(html,stream = True)\n",
    "\n",
    "with open((html.split('/')[-1]), 'wb') as f:\n",
    "    shutil.copyfileobj(r.raw, f)\n",
    "f.close()\n",
    "print(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the top soil moisture from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soil mositure content: SOILM Band 25 - 29\n",
    "#B25: 0-100-DBLY cm\n",
    "#B26: 0-10-DBLY cm\n",
    "#B27: 10-40-DBLY cm\n",
    "#B28: 40-100-DBLY cm\n",
    "#B29: 100-200-DBLY cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the data into weekly 2020\n",
    "sm_dir = \"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\SM_2018_2020\\\\\"\n",
    "smlist = glob.glob(sm_dir+\"2020\\\\*.tif\")\n",
    "smlist.sort()\n",
    "for i in range(52):\n",
    "    no_week=i+1\n",
    "    weekly_arr = 0\n",
    "    weekly_smlist = smlist[i*7*24:(i+1)*7*24]\n",
    "    weekly_smlist.sort()\n",
    "    for sm in weekly_smlist:\n",
    "        ds = gdal.Open(sm)\n",
    "        arr = ds.ReadAsArray()\n",
    "        arr[arr==9999] = np.nan\n",
    "        weekly_arr = weekly_arr+arr\n",
    "    weekly_avg = weekly_arr/(7*24)\n",
    "    if no_week < 10:\n",
    "        no_week_str = '0'+str(no_week)\n",
    "    else:\n",
    "        no_week_str = str(no_week)\n",
    "    fname = 'SM_2020'+no_week_str+\".tif\"\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    TypeIF = gdal.GDT_Float32\n",
    "    geot = ds.GetGeoTransform()\n",
    "    proj = ds.GetProjection()\n",
    "    rows = ds.RasterYSize\n",
    "    cols = ds.RasterXSize\n",
    "    Raster = driver.Create(sm_dir + fname, cols, rows, 1, TypeIF)\n",
    "    Raster.GetRasterBand(1).WriteArray(weekly_avg)\n",
    "    Raster.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    Raster.SetGeoTransform(geot)\n",
    "    Raster.SetProjection(proj)\n",
    "    Raster.FlushCache()\n",
    "    print(fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SM2022 growing season\n",
    "dir_sm = 'R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\Case_Study_2022_Growing_Season\\\\SM\\\\'\n",
    "odir = 'R:/UnitedStates/ForDRI_project-NEW/Case_Study_2022_Growing_Season/SM_tif/'\n",
    "flist_sm = glob.glob(dir_sm+'*.grb')\n",
    "flist_sm.sort()\n",
    "name_list = ['SM_000_100','SM_000_010','SM_010_040','SM_040_100','SM_100_200']\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "TypeIF = gdal.GDT_Float32\n",
    "for f in flist_sm[1320:]:\n",
    "    ds = gdal.Open(f)\n",
    "    geot = ds.GetGeoTransform()\n",
    "    proj = ds.GetProjection()\n",
    "    rows = ds.RasterYSize\n",
    "    cols = ds.RasterXSize\n",
    "    time = os.path.basename(f).split('.')[1][1:]+os.path.basename(f).split('.')[2]\n",
    "    for depth in range(25,30):\n",
    "        new_name = name_list[depth-25]+'_'+time+'.tif'\n",
    "        ds_bands = ds.GetRasterBand(depth)\n",
    "        df_bands_arr = ds_bands.ReadAsArray()\n",
    "        Raster = driver.Create(odir + new_name, cols, rows, 1, TypeIF)\n",
    "        Raster.GetRasterBand(1).WriteArray(df_bands_arr)\n",
    "        Raster.GetRasterBand(1).SetNoDataValue(9999)\n",
    "        Raster.SetGeoTransform(geot)\n",
    "        Raster.SetProjection(proj)\n",
    "        Raster.FlushCache()\n",
    "        print(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the data into weekly level\n",
    "sm_dir = 'R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\Case_Study_2022_Growing_Season\\\\SM_tif\\\\'\n",
    "smlist = glob.glob(sm_dir+\"SM_000_010*.tif\")\n",
    "smlist.sort()\n",
    "\n",
    "for i in range(35):\n",
    "    no_week=i+1\n",
    "    weekly_arr = 0\n",
    "    weekly_smlist = smlist[i*7*24:(i+1)*7*24]\n",
    "    weekly_smlist.sort()\n",
    "    for sm in weekly_smlist:\n",
    "        ds = gdal.Open(sm)\n",
    "        arr = ds.ReadAsArray()\n",
    "        arr[arr==9999] = np.nan\n",
    "        weekly_arr = weekly_arr+arr\n",
    "    weekly_avg = weekly_arr/(7*24)\n",
    "    if no_week < 10:\n",
    "        no_week_str = '0'+str(no_week)\n",
    "    else:\n",
    "        no_week_str = str(no_week)\n",
    "    fname = 'SM_2022'+no_week_str+\".tif\"\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    TypeIF = gdal.GDT_Float32\n",
    "    geot = geoTransform\n",
    "    proj = projection\n",
    "    rows = ds.RasterYSize\n",
    "    cols = ds.RasterXSize\n",
    "    Raster = driver.Create(sm_dir + fname, cols, rows, 1, TypeIF)\n",
    "    Raster.GetRasterBand(1).WriteArray(weekly_avg)\n",
    "    Raster.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    Raster.SetGeoTransform(geot)\n",
    "    Raster.SetProjection(proj)\n",
    "    Raster.FlushCache()\n",
    "    print(fname)\n",
    "del Raster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the SM from 1980-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the SM from 1980 to 2017\n",
    "\n",
    "# check the data scale for the historical data\n",
    "historical_sm = gdal.Open(\"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\nonStanderdizedSM_all\\\\SM198001.tif\").ReadAsArray()\n",
    "new_sm = gdal.Open(\"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\SM_raw_2018_2019_2020\\\\SM_201801.tif\").ReadAsArray()\n",
    "print(\"The range of the old sm data (1980-2017) is: %.2f, %.2f\" %(np.nanmin(historical_sm), np.nanmax(historical_sm))) #(an example)\n",
    "print(\"The range of the new sm data (2018-2020) is: %.2f, %.2f\" %(np.nanmin(new_sm), np.nanmax(new_sm))) #(an example)\n",
    "\n",
    "# rescale the old sm data by deviding by 10\n",
    "historical_sm_list = glob.glob(\"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\nonStanderdizedSM_all\\\\\"+\"*.tif\")\n",
    "historical_sm_list.sort()\n",
    "historical_sm_list = historical_sm_list[:-156]\n",
    "\n",
    "# new directory to save the dataset\n",
    "odir_sm = \"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\scaled_originalSM_0_10cm_1980_2020\\\\\"\n",
    "for f in historical_sm_list:\n",
    "    ds = gdal.Open(f)\n",
    "    fname = os.path.basename(f)[2:]\n",
    "    fname = 'SM_' + fname\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    TypeIF = gdal.GDT_Float32\n",
    "    geot = ds.GetGeoTransform()\n",
    "    proj = ds.GetProjection()\n",
    "    rows = ds.RasterYSize\n",
    "    cols = ds.RasterXSize\n",
    "    Raster = driver.Create(odir_sm + fname, cols, rows, 1, TypeIF)\n",
    "    Raster.GetRasterBand(1).WriteArray(ds.ReadAsArray()/10)\n",
    "    Raster.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    Raster.SetGeoTransform(geot)\n",
    "    Raster.SetProjection(proj)\n",
    "    Raster.FlushCache()\n",
    "    del Raster\n",
    "    \n",
    "new = gdal.Open(\"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\scaled_originalSM_0_10cm_1980_2020\\\\SM_198001.tif\").ReadAsArray()\n",
    "print(\"The range of the scaled old sm data (1980-2017) is: %.2f, %.2f\" %(np.nanmin(new), np.nanmax(new))) #(an example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and std based on the SM from 1980 to 2020\n",
    "# which will be used in the further normalization for 2022 growing season\n",
    "\n",
    "sm_dir = \"R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/scaled_originalSM_0_10cm_1980_2020/\"\n",
    "smlist = glob.glob(sm_dir+\"*.tif\")\n",
    "smlist.sort()\n",
    "\n",
    "# read the projection from the old sm file\n",
    "sm_fdir = \"R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/scaled_originalSM_0_10cm_1980_2020/SM_201711.tif\"\n",
    "ds = gdal.Open(sm_fdir,GA_ReadOnly)\n",
    "proj = ds.GetProjectionRef()\n",
    "geot = ds.GetGeoTransform()\n",
    "\n",
    "sm_arr = []\n",
    "for sm in smlist:\n",
    "    ds = gdal.Open(sm)\n",
    "    arr = ds.ReadAsArray()\n",
    "    arr[arr<-2] = np.nan\n",
    "    sm_arr.append(arr)\n",
    "sm_arr = np.asarray(sm_arr)\n",
    "\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "for i in range(1,53):\n",
    "    if i < 10:\n",
    "        week = '0'+str(i)\n",
    "    else:\n",
    "        week = str(i)\n",
    "    sm_month = sm_arr[i-1::52,:,:]\n",
    "    sm_mean = np.mean(sm_month,0)\n",
    "    mean = driver.Create('R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/SM_MEAN/MEAN_' + week +'.tif', sm_mean.shape[1], sm_mean.shape[0], 1, gdal.GDT_Float32)\n",
    "    mean.GetRasterBand(1).WriteArray(sm_mean.astype(float))\n",
    "    sm_std = np.std(sm_month,0)\n",
    "    std = driver.Create('R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/SM_STD/STD_' + week +'.tif', sm_std.shape[1], sm_std.shape[0], 1, gdal.GDT_Float32)\n",
    "    std.GetRasterBand(1).WriteArray(sm_std.astype(float))\n",
    "    print(week)\n",
    "    mean.FlushCache()\n",
    "    std.FlushCache()\n",
    "    mean.SetGeoTransform(geot)\n",
    "    mean.SetProjection(proj)\n",
    "    std.SetGeoTransform(geot)\n",
    "    std.SetProjection(proj)\n",
    "    del sm_mean, sm_std, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_list = glob.glob('R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/scaled_originalSM_0_10cm_1980_2020/' + '*.tif')\n",
    "sm_list.sort()\n",
    "mean_list = glob.glob('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\SM_MEAN\\\\' + '*.tif')\n",
    "mean_list.sort()\n",
    "std_list = glob.glob('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\SM_STD\\\\' + '*.tif')\n",
    "std_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "for i in range(52):\n",
    "    if i+1 < 10:\n",
    "        week = '0'+str(i+1)\n",
    "    else:\n",
    "        week = str(i+1)\n",
    "    sm_mean = gdal.Open(mean_list[i])\n",
    "    sm_mean_arr = sm_mean.ReadAsArray()\n",
    "    sm_std = gdal.Open(std_list[i])\n",
    "    sm_std_arr = sm_std.ReadAsArray()\n",
    "    for j in range(41):\n",
    "        sm = gdal.Open(sm_list[52*j+i])\n",
    "        sm_arr = sm.ReadAsArray()\n",
    "        projection = sm.GetProjectionRef()\n",
    "        geoTransform = sm.GetGeoTransform()\n",
    "        sm_zscore = (sm_arr-sm_mean_arr)/sm_std_arr\n",
    "        year = str(1980+j)\n",
    "        zscore = driver.Create('R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/stdSM_notcropped_original/SM_' + year+week+'.tif', sm_arr.shape[1], sm_arr.shape[0], 1, gdal.GDT_Float32)\n",
    "        zscore.GetRasterBand(1).WriteArray(sm_zscore)\n",
    "        zscore.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "        zscore.SetGeoTransform(geoTransform)\n",
    "        zscore.SetProjection(projection)\n",
    "        zscore.FlushCache()\n",
    "        del zscore\n",
    "        print('SM_' + year+week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the data into the correct size\n",
    "out_dir = \"R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/stdSM_cropped/\"\n",
    "sm_list = glob.glob('R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/stdSM_notcropped_original/'+'*.tif')\n",
    "sm_list.sort()\n",
    "for idx, f in enumerate(sm_list):\n",
    "    fname = os.path.basename(f)\n",
    "    time = fname[-10:-4]\n",
    "    output = out_dir+fname #output file\n",
    "    data=gdal.Open(f, GA_ReadOnly) #Your data the one you want to clip\n",
    "    gdal.Translate(output,data,format='GTiff',projWin=[-125.0, 50.0, -67.0, 24.0],outputSRS=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the sm from 1980 to 2020 is 0.07, and the std is 0.91 (after the normalization)\n"
     ]
    }
   ],
   "source": [
    "# check the consistency of the data\n",
    "smlist = glob.glob(out_dir+\"*.tif\")\n",
    "sm_arr = []\n",
    "for sm in smlist:\n",
    "    ds = gdal.Open(sm)\n",
    "    arr = ds.ReadAsArray()\n",
    "    arr[arr<-2] = np.nan\n",
    "    sm_arr.append(arr)\n",
    "sm_arr = np.asarray(sm_arr)\n",
    "print('The mean of the sm from 1980 to 2020 is %.2f, and the std is %.2f (after the normalization)'%(np.nanmean(sm_arr),np.nanstd(sm_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the sm from 1980 to 2020 is 23.88, and the std is 6.42, the min and max are 2.00 and 62.43      (before the normalization)\n"
     ]
    }
   ],
   "source": [
    "# check the consistency of the data\n",
    "smlist = glob.glob(\"R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/scaled_originalSM_0_10cm_1980_2020/\"+\"*.tif\")\n",
    "sm_arr = []\n",
    "for sm in smlist:\n",
    "    ds = gdal.Open(sm)\n",
    "    arr = ds.ReadAsArray()\n",
    "    arr[arr<-2] = np.nan\n",
    "    sm_arr.append(arr)\n",
    "sm_arr = np.asarray(sm_arr)\n",
    "print('The mean of the sm from 1980 to 2020 is %.2f, and the std is %.2f, the min and max are %.2f and %.2f\\\n",
    "      (before the normalization)'%(np.nanmean(sm_arr),np.nanstd(sm_arr),np.nanmin(sm_arr),np.nanmax(sm_arr)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SM in the growing season in 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open('R:/UnitedStates/ForDRI_project-NEW/New_Model_2022/Processing/Soil_Moisture/stdSM_cropped/SM_198001.tif',GA_ReadOnly)# your mask raster\n",
    "proj = ds.GetProjectionRef()\n",
    "geot = ds.GetGeoTransform()\n",
    "minx = geot[0]\n",
    "maxy = geot[3]\n",
    "maxx = minx + geot[1] * ds.RasterXSize\n",
    "miny = maxy + geot[5] * ds.RasterYSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_list = glob.glob('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\Case_Study_2022_Growing_Season\\\\SM_tif\\\\' + 'SM_2022*.tif')\n",
    "sm_list.sort()\n",
    "mean_list = glob.glob('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\SM_MEAN\\\\' + '*.tif')\n",
    "mean_list.sort()\n",
    "std_list = glob.glob('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\New_Model_2022\\\\Processing\\\\Soil_Moisture\\\\SM_STD\\\\' + '*.tif')\n",
    "std_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "for i in range(35): # end in 35\n",
    "    if i+1 < 10:\n",
    "        week = '0'+str(i+1)\n",
    "    else:\n",
    "        week = str(i+1)\n",
    "    sm_mean = gdal.Open(mean_list[i])\n",
    "    sm_mean_arr = sm_mean.ReadAsArray()\n",
    "    sm_std = gdal.Open(std_list[i])\n",
    "    sm_std_arr = sm_std.ReadAsArray()\n",
    "    sm = gdal.Open(sm_list[i])\n",
    "    sm_arr = sm.ReadAsArray()\n",
    "    projection = sm.GetProjectionRef()\n",
    "    geoTransform = sm.GetGeoTransform()\n",
    "    sm_zscore = (sm_arr-sm_mean_arr)/sm_std_arr\n",
    "    zscore = driver.Create('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\Case_Study_2022_Growing_Season\\\\stdSM\\\\SM_2022'+week+'.tif', sm_arr.shape[1], sm_arr.shape[0], 1, gdal.GDT_Float32)\n",
    "    zscore.GetRasterBand(1).WriteArray(sm_zscore)\n",
    "    zscore.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    zscore.SetGeoTransform(geoTransform)\n",
    "    zscore.SetProjection(projection)\n",
    "    zscore.FlushCache()\n",
    "    del zscore\n",
    "    print('SM_2022'+week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_list = glob.glob('R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\Case_Study_2022_Growing_Season\\\\stdSM\\\\' + '*.tif')\n",
    "sm_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"R:\\\\UnitedStates\\\\ForDRI_project-NEW\\\\Case_Study_2022_Growing_Season\\\\stdSM_Masked\\\\\"\n",
    "for idx, f in enumerate(sm_list):\n",
    "    fname = os.path.basename(f)\n",
    "    time = fname[-10:-4]\n",
    "    output = out_dir+fname #output file\n",
    "    data=gdal.Open(f, GA_ReadOnly) #Your data the one you want to clip\n",
    "    gdal.Translate(output,data,format='GTiff',projWin=[-125.0, 50.0, -67.0, 24.0],outputSRS=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-125.0, 50.0, -67.0, 24.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SM projWin\n",
    "[minx,maxy,maxx,miny]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SM proj\n",
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-125.0, 0.125, 0.0, 50.0, 0.0, -0.125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SM geot\n",
    "geot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7fce67f7bf81c6c01801418c0740e5ed8883a3338285553951947b9d9952603"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mywork')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
